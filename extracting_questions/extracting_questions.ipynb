{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extracting-questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI8vbNx632VQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a11953dc-7ced-47e9-d0cc-230a2dc5f237"
      },
      "source": [
        "#getting annotated file\n",
        "!gdown https://drive.google.com/u/0/uc?id=1vrVeNraqXpBtoYy53PB4sD7PFYpq6F2y"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1vrVeNraqXpBtoYy53PB4sD7PFYpq6F2y\n",
            "To: /content/stanford-ner-4.0.0/for_ner.tsv\n",
            "\r  0% 0.00/2.03k [00:00<?, ?B/s]\r100% 2.03k/2.03k [00:00<00:00, 4.99MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5nHH18a68WU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3474dc2d-d5e4-493e-96f4-6b401b807a79"
      },
      "source": [
        "#custom dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('for_ner.tsv', sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>What</th>\n",
              "      <th>QUESTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is</td>\n",
              "      <td>QUESTION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>your</td>\n",
              "      <td>QUESTION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>compliance?</td>\n",
              "      <td>QUESTION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Will</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          What  QUESTION\n",
              "0           is  QUESTION\n",
              "1         your  QUESTION\n",
              "2  compliance?  QUESTION\n",
              "3            .         O\n",
              "4         Will         O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvZKyf5P-5e4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "c9cf6f40-80a4-47c1-ae32-a2996a54aae1"
      },
      "source": [
        "#importing stanford ner\n",
        "!wget https://nlp.stanford.edu/software/stanford-ner-4.0.0.zip\n",
        "!apt-get install unzip\n",
        "!unzip stanford-ner-4.0.0.zip"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-25 21:59:58--  https://nlp.stanford.edu/software/stanford-ner-4.0.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180643763 (172M) [application/zip]\n",
            "Saving to: ‘stanford-ner-4.0.0.zip’\n",
            "\n",
            "stanford-ner-4.0.0. 100%[===================>] 172.27M  4.71MB/s    in 63s     \n",
            "\n",
            "2020-07-25 22:01:02 (2.72 MB/s) - ‘stanford-ner-4.0.0.zip’ saved [180643763/180643763]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Archive:  stanford-ner-4.0.0.zip\n",
            "   creating: stanford-ner-4.0.0/\n",
            "  inflating: stanford-ner-4.0.0/ner-gui.sh  \n",
            "  inflating: stanford-ner-4.0.0/build.xml  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner.jar  \n",
            "  inflating: stanford-ner-4.0.0/sample-conll-file.txt  \n",
            "  inflating: stanford-ner-4.0.0/README.txt  \n",
            "  inflating: stanford-ner-4.0.0/NERDemo.java  \n",
            "  inflating: stanford-ner-4.0.0/sample.ner.txt  \n",
            "  inflating: stanford-ner-4.0.0/ner.sh  \n",
            "  inflating: stanford-ner-4.0.0/LICENSE.txt  \n",
            "   creating: stanford-ner-4.0.0/lib/\n",
            "  inflating: stanford-ner-4.0.0/lib/joda-time.jar  \n",
            "  inflating: stanford-ner-4.0.0/lib/jollyday-0.4.9.jar  \n",
            "  inflating: stanford-ner-4.0.0/lib/stanford-ner-resources.jar  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0-sources.jar  \n",
            "  inflating: stanford-ner-4.0.0/sample.txt  \n",
            "  inflating: stanford-ner-4.0.0/ner-gui.command  \n",
            "  inflating: stanford-ner-4.0.0/ner.bat  \n",
            "  inflating: stanford-ner-4.0.0/ner-gui.bat  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0-javadoc.jar  \n",
            "   creating: stanford-ner-4.0.0/classifiers/\n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.conll.4class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/example.serialized.ncc.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.all.3class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.conll.4class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.all.3class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/example.serialized.ncc.ncc.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/sample-w-time.txt  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0.jar  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VERDH4n7gfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1c31aeb6-75ad-4fac-8508-1750e4d72ea8"
      },
      "source": [
        "#install JAVA\n",
        "!apt-get install openjdk-8-jdk\n",
        "!echo $JAVA_HOME"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 61%\r\rReading package lists... 61%\r\rReading package lists... 62%\r\rReading package lists... 62%\r\rReading package lists... 65%\r\rReading package lists... 70%\r\rReading package lists... 70%\r\rReading package lists... 71%\r\rReading package lists... 71%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 86%\r\rReading package lists... 86%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "openjdk-8-jdk is already the newest version (8u252-b09-1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLdJlBX19hek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "8560c833-96a0-45eb-8642-e6b2bedc537b"
      },
      "source": [
        "#trying the stanford NER on a random sentence\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "\n",
        "sentence = u\"Twenty miles east of Reno, Nev., \" \\\n",
        "    \"where packs of wild mustangs roam free through \" \\\n",
        "    \"the parched landscape, Tesla Gigafactory 1 \" \\\n",
        "    \"sprawls near Interstate 80.\"\n",
        "\n",
        "jar = 'stanford-ner-4.0.0/stanford-ner-4.0.0.jar'\n",
        "model = 'stanford-ner-4.0.0/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
        "\n",
        "# Prepare NER tagger with english model\n",
        "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
        "\n",
        "# Tokenize: Split sentence into words\n",
        "words = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Run NER tagger on words\n",
        "print(ner_tagger.tag(words))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('Twenty', 'O'), ('miles', 'O'), ('east', 'O'), ('of', 'O'), ('Reno', 'LOCATION'), (',', 'O'), ('Nev.', 'LOCATION'), (',', 'O'), ('where', 'O'), ('packs', 'O'), ('of', 'O'), ('wild', 'O'), ('mustangs', 'O'), ('roam', 'O'), ('free', 'O'), ('through', 'O'), ('the', 'O'), ('parched', 'O'), ('landscape', 'O'), (',', 'O'), ('Tesla', 'ORGANIZATION'), ('Gigafactory', 'ORGANIZATION'), ('1', 'O'), ('sprawls', 'O'), ('near', 'O'), ('Interstate', 'LOCATION'), ('80', 'LOCATION'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "przTtrqUrLfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0f4a34be-9788-41e6-b3ec-7ad7fd35971e"
      },
      "source": [
        "#generating trainer file\n",
        "%cd stanford-ner-4.0.0\n",
        "!gdown https://drive.google.com/u/0/uc?id=1vrVeNraqXpBtoYy53PB4sD7PFYpq6F2y\n",
        "\n",
        "s = \"trainFile = for_ner.tsv \\\n",
        "\\nserializeTo = my-ner-model.ser.gz \\\n",
        "\\nmap = word=0,answer=1 \\\n",
        "\\n \\\n",
        "\\nuseClassFeature=true \\\n",
        "\\nuseWord=true \\\n",
        "\\nuseNGrams=true \\\n",
        "\\nnoMidNGrams=true \\\n",
        "\\nmaxNGramLeng=6 \\\n",
        "\\nusePrev=true \\\n",
        "\\nuseNext=true \\\n",
        "\\nuseSequences=true \\\n",
        "\\nusePrevSequences=true \\\n",
        "\\nmaxLeft=1 \\\n",
        "\\nuseTypeSeqs=true \\\n",
        "\\nuseTypeSeqs2=true \\\n",
        "\\nuseTypeySequences=true \\\n",
        "\\nwordShape=chris2useLC \\\n",
        "\\nuseDisjunctive=true\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stanford-ner-4.0.0/stanford-ner-4.0.0\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1vrVeNraqXpBtoYy53PB4sD7PFYpq6F2y\n",
            "To: /content/stanford-ner-4.0.0/stanford-ner-4.0.0/for_ner.tsv\n",
            "100% 2.03k/2.03k [00:00<00:00, 3.53MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AuOkvpwr-O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('prop.txt', 'w')\n",
        "f.write(s)\n",
        "f.close()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Zn4DiytsX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "635ace09-2df7-4ab3-8c8d-76c612af8c2a"
      },
      "source": [
        "#training custom ner model\n",
        "\n",
        "!java -cp \"stanford-ner.jar:lib/*\" -mx4g edu.stanford.nlp.ie.crf.CRFClassifier -prop /content/prop.txt\n",
        "#!ls\n",
        "#%cd .."
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Invoked on Sat Jul 25 22:01:26 UTC 2020 with arguments: -prop /content/prop.txt\n",
            "useTypeSeqs2=true\n",
            "noMidNGrams=true\n",
            "trainFile=/content/for_ner.tsv\n",
            "maxNGramLeng=6\n",
            "maxLeft=1\n",
            "serializeTo=my-ner-model.ser.gz\n",
            "wordShape=chris2useLC\n",
            "useDisjunctive=true\n",
            "useClassFeature=true\n",
            "useNGrams=true\n",
            "useNext=true\n",
            "usePrev=true\n",
            "useTypeySequences=true\n",
            "usePrevSequences=true\n",
            "useTypeSeqs=true\n",
            "useSequences=true\n",
            "map=word=0,answer=1\n",
            "useWord=true\n",
            "numFeatures = 2591\n",
            "Time to convert docs to feature indices: 0.1 seconds\n",
            "Current memory used: 8m\n",
            "numClasses: 2 [0=O,1=QUESTION]\n",
            "numDocuments: 1\n",
            "numDatums: 193\n",
            "numFeatures: 2591\n",
            "Time to convert docs to data/labels: 0.0 seconds\n",
            "Current memory used: 10m\n",
            "Running gradient on 2 threads\n",
            "numWeights: 6346\n",
            "QNMinimizer called on double function of 6346 variables, using M = 25.\n",
            "               An explanation of the output:\n",
            "Iter           The number of iterations\n",
            "evals          The number of function evaluations\n",
            "SCALING        <D> Diagonal scaling was used; <I> Scaled Identity\n",
            "LINESEARCH     [## M steplength]  Minpack linesearch\n",
            "                   1-Function value was too high\n",
            "                   2-Value ok, gradient positive, positive curvature\n",
            "                   3-Value ok, gradient negative, positive curvature\n",
            "                   4-Value ok, gradient negative, negative curvature\n",
            "               [.. B]  Backtracking\n",
            "VALUE          The current function value\n",
            "TIME           Total elapsed time\n",
            "|GNORM|        The current norm of the gradient\n",
            "{RELNORM}      The ratio of the current to initial gradient norms\n",
            "AVEIMPROVE     The average improvement / current value\n",
            "EVALSCORE      The last available eval score\n",
            " \n",
            "Iter ## evals ## <SCALING> [LINESEARCH] VALUE TIME |GNORM| {RELNORM} AVEIMPROVE EVALSCORE\n",
            "\n",
            "Iter 1 evals 1 <D> [113M 4.084E-3] 1.154E3 0.06s |1.189E2| {4.260E-1} 0.000E0 - \n",
            "Iter 2 evals 5 <D> [M 1.000E0] 1.120E3 0.07s |9.371E1| {3.358E-1} 1.530E-2 - \n",
            "Iter 3 evals 6 <D> [M 1.000E0] 1.037E3 0.09s |2.876E2| {1.030E0} 3.775E-2 - \n",
            "Iter 4 evals 7 <D> [M 1.000E0] 9.328E2 0.10s |4.847E1| {1.737E-1} 5.938E-2 - \n",
            "Iter 5 evals 8 <D> [M 1.000E0] 8.518E2 0.12s |4.177E1| {1.497E-1} 7.103E-2 - \n",
            "Iter 6 evals 9 <D> [M 1.000E0] 5.225E2 0.14s |8.664E1| {3.104E-1} 2.016E-1 - \n",
            "Iter 7 evals 10 <D> [M 1.000E0] 3.116E2 0.17s |3.931E1| {1.409E-1} 3.863E-1 - \n",
            "Iter 8 evals 11 <D> [M 1.000E0] 2.218E2 0.18s |2.639E1| {9.455E-2} 5.255E-1 - \n",
            "Iter 9 evals 12 <D> [M 1.000E0] 1.187E2 0.19s |1.543E1| {5.529E-2} 9.693E-1 - \n",
            "Iter 10 evals 13 <D> [M 1.000E0] 4.373E1 0.21s |1.266E1| {4.538E-2} 2.539E0 - \n",
            "Iter 11 evals 14 <D> [1M 2.753E-1] 3.706E1 0.24s |1.381E1| {4.948E-2} 2.923E0 - \n",
            "Iter 12 evals 16 <D> [1M 8.905E-2] 3.238E1 0.27s |1.167E1| {4.181E-2} 3.102E0 - \n",
            "Iter 13 evals 18 <D> [M 1.000E0] 2.693E1 0.29s |8.388E0| {3.005E-2} 3.364E0 - \n",
            "Iter 14 evals 19 <D> [1M 1.203E-1] 2.590E1 0.31s |1.234E1| {4.422E-2} 3.189E0 - \n",
            "Iter 15 evals 21 <D> [M 1.000E0] 2.325E1 0.33s |5.132E1| {1.839E-1} 2.148E0 - \n",
            "Iter 16 evals 22 <D> [M 1.000E0] 1.904E1 0.33s |7.664E0| {2.746E-2} 1.536E0 - \n",
            "Iter 17 evals 23 <D> [M 1.000E0] 1.796E1 0.34s |7.789E0| {2.791E-2} 1.135E0 - \n",
            "Iter 18 evals 24 <D> [2M 4.200E-1] 1.536E1 0.34s |9.369E0| {3.357E-2} 6.728E-1 - \n",
            "Iter 19 evals 26 <D> [1M 2.923E-1] 1.401E1 0.37s |1.245E1| {4.461E-2} 2.122E-1 - \n",
            "Iter 20 evals 28 <D> [M 1.000E0] 1.236E1 0.37s |1.879E1| {6.733E-2} 1.999E-1 - \n",
            "Iter 21 evals 29 <D> [M 1.000E0] 1.093E1 0.38s |9.335E0| {3.345E-2} 1.962E-1 - \n",
            "Iter 22 evals 30 <D> [1M 3.952E-1] 1.003E1 0.39s |1.017E1| {3.645E-2} 1.684E-1 - \n",
            "Iter 23 evals 32 <D> [M 1.000E0] 9.733E0 0.39s |4.927E0| {1.765E-2} 1.661E-1 - \n",
            "Iter 24 evals 33 <D> [M 1.000E0] 9.308E0 0.40s |4.719E0| {1.691E-2} 1.497E-1 - \n",
            "Iter 25 evals 34 <D> [M 1.000E0] 8.904E0 0.40s |7.783E0| {2.789E-2} 1.139E-1 - \n",
            "Iter 26 evals 35 <D> [M 1.000E0] 8.575E0 0.41s |4.671E0| {1.674E-2} 1.095E-1 - \n",
            "Iter 27 evals 36 <D> [M 1.000E0] 8.055E0 0.41s |3.437E0| {1.231E-2} 9.072E-2 - \n",
            "Iter 28 evals 37 <D> [M 1.000E0] 7.365E0 0.41s |3.332E0| {1.194E-2} 9.018E-2 - \n",
            "Iter 29 evals 38 <D> [M 1.000E0] 6.817E0 0.42s |2.888E0| {1.035E-2} 8.127E-2 - \n",
            "Iter 30 evals 39 <D> [2M 4.664E-1] 6.137E0 0.43s |2.764E0| {9.904E-3} 7.812E-2 - \n",
            "Iter 31 evals 41 <D> [M 1.000E0] 5.568E0 0.43s |1.864E0| {6.678E-3} 8.021E-2 - \n",
            "Iter 32 evals 42 <D> [M 1.000E0] 5.248E0 0.44s |1.007E0| {3.610E-3} 8.546E-2 - \n",
            "Iter 33 evals 43 <D> [M 1.000E0] 5.122E0 0.44s |9.611E-1| {3.444E-3} 8.173E-2 - \n",
            "Iter 34 evals 44 <D> [M 1.000E0] 5.056E0 0.45s |7.038E-1| {2.522E-3} 7.609E-2 - \n",
            "Iter 35 evals 45 <D> [M 1.000E0] 5.034E0 0.45s |6.724E-1| {2.409E-3} 7.035E-2 - \n",
            "Iter 36 evals 46 <D> [M 1.000E0] 5.021E0 0.45s |5.067E-1| {1.816E-3} 6.042E-2 - \n",
            "Iter 37 evals 47 <D> [M 1.000E0] 5.016E0 0.46s |3.427E-1| {1.228E-3} 4.685E-2 - \n",
            "Iter 38 evals 48 <D> [M 1.000E0] 5.011E0 0.46s |3.200E-1| {1.147E-3} 3.604E-2 - \n",
            "Iter 39 evals 49 <D> [M 1.000E0] 5.008E0 0.46s |2.471E-1| {8.853E-4} 2.254E-2 - \n",
            "Iter 40 evals 50 <D> [M 1.000E0] 5.006E0 0.47s |1.803E-1| {6.461E-4} 1.123E-2 - \n",
            "Iter 41 evals 51 <D> [M 1.000E0] 5.004E0 0.47s |1.022E-1| {3.661E-4} 4.863E-3 - \n",
            "Iter 42 evals 52 <D> [1M 4.015E-1] 5.004E0 0.48s |5.017E-2| {1.797E-4} 2.362E-3 - \n",
            "Iter 43 evals 54 <D> [M 1.000E0] 5.003E0 0.48s |2.397E-2| {8.590E-5} 1.060E-3 - \n",
            "Iter 44 evals 55 <D> [M 1.000E0] 5.003E0 0.48s |1.320E-2| {4.730E-5} 6.167E-4 - \n",
            "Iter 45 evals 56 <D> [M 1.000E0] 5.003E0 0.49s |7.479E-3| {2.680E-5} 3.663E-4 - \n",
            "Iter 46 evals 57 <D> [M 1.000E0] 5.003E0 0.49s |5.576E-3| {1.998E-5} 2.480E-4 - \n",
            "Iter 47 evals 58 <D> [M 1.000E0] 5.003E0 0.49s |2.544E-3| {9.114E-6} 1.583E-4 - \n",
            "QNMinimizer terminated due to average improvement: | newest_val - previous_val | / |newestVal| < TOL \n",
            "Total time spent in optimization: 0.50s\n",
            "CRFClassifier training ... done [0.7 sec].\n",
            "Serializing classifier to my-ner-model.ser.gz... done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CQq_IuQul4t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b4249c9d-c23b-49b4-a6e7-fa46fe280fea"
      },
      "source": [
        "#testing our new developed NER\n",
        "sentence = \"This is a sample text I am writing to test the usefullness of the NER tagger. Few things to note are that I am Going to ask two questions. \\\n",
        "            first being What is your Compliance? and the second one will be Do we need to have a CRM solution to use Avnio?\"\n",
        "jar = 'stanford-ner.jar'\n",
        "model = 'my-ner-model.ser.gz'\n",
        "\n",
        "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
        "\n",
        "words = nltk.word_tokenize(sentence)\n",
        "result = ner_tagger.tag(words)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVbXMuxMwV17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "b82c6b1e-db24-4ae5-d65a-1ea607cae9fd"
      },
      "source": [
        "#adding a dummy at the end to define EOF\n",
        "#NER Results\n",
        "result.append(('.','O'))\n",
        "result"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'O'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('sample', 'O'),\n",
              " ('text', 'O'),\n",
              " ('I', 'O'),\n",
              " ('am', 'O'),\n",
              " ('writing', 'O'),\n",
              " ('to', 'O'),\n",
              " ('test', 'O'),\n",
              " ('the', 'O'),\n",
              " ('usefullness', 'O'),\n",
              " ('of', 'O'),\n",
              " ('the', 'O'),\n",
              " ('NER', 'O'),\n",
              " ('tagger', 'O'),\n",
              " ('.', 'O'),\n",
              " ('Few', 'O'),\n",
              " ('things', 'O'),\n",
              " ('to', 'O'),\n",
              " ('note', 'O'),\n",
              " ('are', 'O'),\n",
              " ('that', 'O'),\n",
              " ('I', 'O'),\n",
              " ('am', 'O'),\n",
              " ('Going', 'O'),\n",
              " ('to', 'O'),\n",
              " ('ask', 'O'),\n",
              " ('two', 'O'),\n",
              " ('questions', 'O'),\n",
              " ('.', 'O'),\n",
              " ('first', 'O'),\n",
              " ('being', 'O'),\n",
              " ('What', 'QUESTION'),\n",
              " ('is', 'QUESTION'),\n",
              " ('your', 'QUESTION'),\n",
              " ('Compliance', 'QUESTION'),\n",
              " ('?', 'QUESTION'),\n",
              " ('and', 'O'),\n",
              " ('the', 'O'),\n",
              " ('second', 'O'),\n",
              " ('one', 'O'),\n",
              " ('will', 'O'),\n",
              " ('be', 'O'),\n",
              " ('Do', 'QUESTION'),\n",
              " ('we', 'QUESTION'),\n",
              " ('need', 'QUESTION'),\n",
              " ('to', 'QUESTION'),\n",
              " ('have', 'QUESTION'),\n",
              " ('a', 'QUESTION'),\n",
              " ('CRM', 'QUESTION'),\n",
              " ('solution', 'QUESTION'),\n",
              " ('to', 'QUESTION'),\n",
              " ('use', 'QUESTION'),\n",
              " ('Avnio', 'QUESTION'),\n",
              " ('?', 'QUESTION'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jfQ7z4A3nGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting the chunks from NER\n",
        "ques = []\n",
        "i=0\n",
        "while i<len(result):\n",
        "  if result[i][1]=='QUESTION':\n",
        "    s=''\n",
        "    while result[i][1]!='O':  \n",
        "      s=s+result[i][0]+' '\n",
        "      i=i+1\n",
        "    ques.append(s.strip())\n",
        "  i=i+1\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q9Eoy9v8Urm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e55be855-6880-4135-ab3a-245a3ce13f02"
      },
      "source": [
        "#the questions asked in the sample string were:\n",
        "#next we shall use multi label classification to caregorise these questions type\n",
        "ques"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is your Compliance ?',\n",
              " 'Do we need to have a CRM solution to use Avnio ?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgPDoJPG8YUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}