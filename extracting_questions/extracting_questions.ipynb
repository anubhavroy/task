{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extracting_questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI8vbNx632VQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "787b8c88-5a5a-4751-bc91-fab587f5787c"
      },
      "source": [
        "#getting annotated file\n",
        "!gdown https://drive.google.com/u/0/uc?id=1vrVeNraqXpBtoYy53PB4sD7PFYpq6F2y"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1vrVeNraqXpBtoYy53PB4sD7PFYpq6F2y\n",
            "To: /content/for_ner.tsv\n",
            "\r  0% 0.00/2.03k [00:00<?, ?B/s]\r100% 2.03k/2.03k [00:00<00:00, 3.80MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5nHH18a68WU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ffdbfff7-65d8-4d82-bdf8-b3380897da25"
      },
      "source": [
        "#custom dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('for_ner.tsv', sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>What</th>\n",
              "      <th>QUESTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is</td>\n",
              "      <td>QUESTION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>your</td>\n",
              "      <td>QUESTION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>compliance?</td>\n",
              "      <td>QUESTION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Will</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          What  QUESTION\n",
              "0           is  QUESTION\n",
              "1         your  QUESTION\n",
              "2  compliance?  QUESTION\n",
              "3            .         O\n",
              "4         Will         O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvZKyf5P-5e4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "25d72823-ede6-4950-e283-337d983b76de"
      },
      "source": [
        "#importing stanford ner\n",
        "!wget https://nlp.stanford.edu/software/stanford-ner-4.0.0.zip\n",
        "!apt-get install unzip\n",
        "!unzip stanford-ner-4.0.0.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-26 20:16:31--  https://nlp.stanford.edu/software/stanford-ner-4.0.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180643763 (172M) [application/zip]\n",
            "Saving to: ‘stanford-ner-4.0.0.zip’\n",
            "\n",
            "stanford-ner-4.0.0. 100%[===================>] 172.27M  38.0MB/s    in 5.9s    \n",
            "\n",
            "2020-07-26 20:16:37 (29.4 MB/s) - ‘stanford-ner-4.0.0.zip’ saved [180643763/180643763]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Archive:  stanford-ner-4.0.0.zip\n",
            "   creating: stanford-ner-4.0.0/\n",
            "  inflating: stanford-ner-4.0.0/ner-gui.sh  \n",
            "  inflating: stanford-ner-4.0.0/build.xml  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner.jar  \n",
            "  inflating: stanford-ner-4.0.0/sample-conll-file.txt  \n",
            "  inflating: stanford-ner-4.0.0/README.txt  \n",
            "  inflating: stanford-ner-4.0.0/NERDemo.java  \n",
            "  inflating: stanford-ner-4.0.0/sample.ner.txt  \n",
            "  inflating: stanford-ner-4.0.0/ner.sh  \n",
            "  inflating: stanford-ner-4.0.0/LICENSE.txt  \n",
            "   creating: stanford-ner-4.0.0/lib/\n",
            "  inflating: stanford-ner-4.0.0/lib/joda-time.jar  \n",
            "  inflating: stanford-ner-4.0.0/lib/jollyday-0.4.9.jar  \n",
            "  inflating: stanford-ner-4.0.0/lib/stanford-ner-resources.jar  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0-sources.jar  \n",
            "  inflating: stanford-ner-4.0.0/sample.txt  \n",
            "  inflating: stanford-ner-4.0.0/ner-gui.command  \n",
            "  inflating: stanford-ner-4.0.0/ner.bat  \n",
            "  inflating: stanford-ner-4.0.0/ner-gui.bat  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0-javadoc.jar  \n",
            "   creating: stanford-ner-4.0.0/classifiers/\n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.conll.4class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/example.serialized.ncc.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.all.3class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.conll.4class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.all.3class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/example.serialized.ncc.ncc.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/sample-w-time.txt  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0.jar  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VERDH4n7gfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5736709-df65-4ed0-f5f9-134aa9f55877"
      },
      "source": [
        "#install JAVA\n",
        "!apt-get install openjdk-8-jdk\n",
        "!echo $JAVA_HOME"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 6%\r\rReading package lists... 61%\r\rReading package lists... 61%\r\rReading package lists... 62%\r\rReading package lists... 62%\r\rReading package lists... 70%\r\rReading package lists... 70%\r\rReading package lists... 71%\r\rReading package lists... 71%\r\rReading package lists... 79%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 80%\r\rReading package lists... 86%\r\rReading package lists... 86%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 10 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 40.7 MB of archives.\n",
            "After this operation, 153 MB of additional disk space will be used.\n",
            "\r0% [Working]\r            \rGet:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "\r0% [1 libxxf86dga1 13.7 kB/13.7 kB 100%]\r                                        \r2% [Working]\r            \rGet:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "\r2% [2 fonts-dejavu-core 5,508 B/1,041 kB 1%]\r                                            \r6% [Working]\r            \rGet:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "\r6% [3 fonts-dejavu-extra 0 B/1,953 kB 0%]\r                                         \r12% [Working]\r             \rGet:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "\r12% [4 x11-utils 0 B/196 kB 0%]\r                               \r14% [Working]\r             \rGet:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "\r14% [5 libatk-wrapper-java 2,743 B/34.7 kB 8%]\r                                              \r16% [Working]\r             \rGet:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "\r16% [6 libatk-wrapper-java-jni 28.3 kB/28.3 kB 100%]\r                                                    \r18% [Waiting for headers]\r                         \rGet:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u252-b09-1~18.04 [27.5 MB]\n",
            "\r18% [7 openjdk-8-jre-headless 4,367 B/27.5 MB 0%]\r56% [7 openjdk-8-jre-headless 19.0 MB/27.5 MB 69%]\r                                                  \r74% [Working]\r             \rGet:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u252-b09-1~18.04 [69.8 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u252-b09-1~18.04 [8,250 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u252-b09-1~18.04 [1,622 kB]\n",
            "Fetched 40.7 MB in 2s (23.3 MB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../1-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../2-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../3-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../4-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../5-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../6-openjdk-8-jre-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../7-openjdk-8-jre_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../8-openjdk-8-jdk-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../9-openjdk-8-jdk_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u252-b09-1~18.04) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLdJlBX19hek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "9f9e77cf-ae16-438c-fac2-3389123a550a"
      },
      "source": [
        "#trying the stanford NER on a random sentence\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "\n",
        "sentence = u\"Twenty miles east of Reno, Nev., \" \\\n",
        "    \"where packs of wild mustangs roam free through \" \\\n",
        "    \"the parched landscape, Tesla Gigafactory 1 \" \\\n",
        "    \"sprawls near Interstate 80.\"\n",
        "\n",
        "jar = 'stanford-ner-4.0.0/stanford-ner-4.0.0.jar'\n",
        "model = 'stanford-ner-4.0.0/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
        "\n",
        "# Prepare NER tagger with english model\n",
        "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
        "\n",
        "# Tokenize: Split sentence into words\n",
        "words = nltk.word_tokenize(sentence)\n",
        "\n",
        "# Run NER tagger on words\n",
        "print(ner_tagger.tag(words))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('Twenty', 'O'), ('miles', 'O'), ('east', 'O'), ('of', 'O'), ('Reno', 'LOCATION'), (',', 'O'), ('Nev.', 'LOCATION'), (',', 'O'), ('where', 'O'), ('packs', 'O'), ('of', 'O'), ('wild', 'O'), ('mustangs', 'O'), ('roam', 'O'), ('free', 'O'), ('through', 'O'), ('the', 'O'), ('parched', 'O'), ('landscape', 'O'), (',', 'O'), ('Tesla', 'ORGANIZATION'), ('Gigafactory', 'ORGANIZATION'), ('1', 'O'), ('sprawls', 'O'), ('near', 'O'), ('Interstate', 'LOCATION'), ('80', 'LOCATION'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "przTtrqUrLfD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "40de0064-1d85-4e10-b299-c654228e5db4"
      },
      "source": [
        "#generating trainer file\n",
        "%cd stanford-ner-4.0.0\n",
        "!gdown https://drive.google.com/u/0/uc?id=1vrVeNraqXpBtoYy53PB4sD7PFYpq6F2y\n",
        "\n",
        "s = \"trainFile = for_ner.tsv \\\n",
        "\\nserializeTo = my-ner-model.ser.gz \\\n",
        "\\nmap = word=0,answer=1 \\\n",
        "\\n \\\n",
        "\\nuseClassFeature=true \\\n",
        "\\nuseWord=true \\\n",
        "\\nuseNGrams=true \\\n",
        "\\nnoMidNGrams=true \\\n",
        "\\nmaxNGramLeng=6 \\\n",
        "\\nusePrev=true \\\n",
        "\\nuseNext=true \\\n",
        "\\nuseSequences=true \\\n",
        "\\nusePrevSequences=true \\\n",
        "\\nmaxLeft=1 \\\n",
        "\\nuseTypeSeqs=true \\\n",
        "\\nuseTypeSeqs2=true \\\n",
        "\\nuseTypeySequences=true \\\n",
        "\\nwordShape=chris2useLC \\\n",
        "\\nuseDisjunctive=true\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stanford-ner-4.0.0\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1vrVeNraqXpBtoYy53PB4sD7PFYpq6F2y\n",
            "To: /content/stanford-ner-4.0.0/for_ner.tsv\n",
            "100% 2.03k/2.03k [00:00<00:00, 3.23MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AuOkvpwr-O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('prop.txt', 'w')\n",
        "f.write(s)\n",
        "f.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Zn4DiytsX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6d56c279-0d5b-4783-d86e-e3fe710e0d12"
      },
      "source": [
        "#training custom ner model\n",
        "\n",
        "!java -cp \"stanford-ner.jar:lib/*\" -mx4g edu.stanford.nlp.ie.crf.CRFClassifier -prop prop.txt\n",
        "#!ls\n",
        "#%cd .."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Invoked on Sun Jul 26 20:17:25 UTC 2020 with arguments: -prop /content/prop.txt\n",
            "Exception in thread \"main\" edu.stanford.nlp.io.RuntimeIOException: argsToProperties could not read properties file: /content/prop.txt\n",
            "\tat edu.stanford.nlp.util.StringUtils.argsToProperties(StringUtils.java:1060)\n",
            "\tat edu.stanford.nlp.ie.crf.CRFClassifier.main(CRFClassifier.java:2912)\n",
            "Caused by: java.io.IOException: Unable to open \"/content/prop.txt\" as class path, filename or URL\n",
            "\tat edu.stanford.nlp.io.IOUtils.getInputStreamFromURLOrClasspathOrFileSystem(IOUtils.java:481)\n",
            "\tat edu.stanford.nlp.io.IOUtils.readerFromString(IOUtils.java:618)\n",
            "\tat edu.stanford.nlp.util.StringUtils.argsToProperties(StringUtils.java:1051)\n",
            "\t... 1 more\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CQq_IuQul4t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "b2228bcf-0631-46bc-ad6d-aceba835a978"
      },
      "source": [
        "#testing our new developed NER\n",
        "sentence = \"This is a sample text I am writing to test the usefullness of the NER tagger. Few things to note are that I am Going to ask two questions. \\\n",
        "            first being What is your Compliance? and the second one will be Do we need to have a CRM solution to use Avnio?\"\n",
        "jar = 'stanford-ner.jar'\n",
        "model = 'my-ner-model.ser.gz'\n",
        "\n",
        "ner_tagger = StanfordNERTagger(model, jar, encoding='utf8')\n",
        "\n",
        "words = nltk.word_tokenize(sentence)\n",
        "result = ner_tagger.tag(words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-88096fea4b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'my-ner-model.ser.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mner_tagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordNERTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStanfordNERTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m         self._stanford_model = find_file(model_filename,\n\u001b[1;32m     69\u001b[0m                                          \u001b[0menv_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'STANFORD_MODELS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                          verbose=verbose)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/__init__.py\u001b[0m in \u001b[0;36mfind_file\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose)\u001b[0m\n\u001b[1;32m    573\u001b[0m         file_names=None, url=None, verbose=False):\n\u001b[1;32m    574\u001b[0m     return next(find_file_iter(filename, env_vars, searchpath,\n\u001b[0;32m--> 575\u001b[0;31m                                file_names, url, verbose))\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/__init__.py\u001b[0m in \u001b[0;36mfind_file_iter\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[1;32m    567\u001b[0m                         (filename, url))\n\u001b[1;32m    568\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the my-ner-model.ser.gz file!\nUse software specific configuration paramaters or set the STANFORD_MODELS environment variable.\n==========================================================================="
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVbXMuxMwV17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "b82c6b1e-db24-4ae5-d65a-1ea607cae9fd"
      },
      "source": [
        "#adding a dummy at the end to define EOF\n",
        "#NER Results\n",
        "result.append(('.','O'))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'O'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('sample', 'O'),\n",
              " ('text', 'O'),\n",
              " ('I', 'O'),\n",
              " ('am', 'O'),\n",
              " ('writing', 'O'),\n",
              " ('to', 'O'),\n",
              " ('test', 'O'),\n",
              " ('the', 'O'),\n",
              " ('usefullness', 'O'),\n",
              " ('of', 'O'),\n",
              " ('the', 'O'),\n",
              " ('NER', 'O'),\n",
              " ('tagger', 'O'),\n",
              " ('.', 'O'),\n",
              " ('Few', 'O'),\n",
              " ('things', 'O'),\n",
              " ('to', 'O'),\n",
              " ('note', 'O'),\n",
              " ('are', 'O'),\n",
              " ('that', 'O'),\n",
              " ('I', 'O'),\n",
              " ('am', 'O'),\n",
              " ('Going', 'O'),\n",
              " ('to', 'O'),\n",
              " ('ask', 'O'),\n",
              " ('two', 'O'),\n",
              " ('questions', 'O'),\n",
              " ('.', 'O'),\n",
              " ('first', 'O'),\n",
              " ('being', 'O'),\n",
              " ('What', 'QUESTION'),\n",
              " ('is', 'QUESTION'),\n",
              " ('your', 'QUESTION'),\n",
              " ('Compliance', 'QUESTION'),\n",
              " ('?', 'QUESTION'),\n",
              " ('and', 'O'),\n",
              " ('the', 'O'),\n",
              " ('second', 'O'),\n",
              " ('one', 'O'),\n",
              " ('will', 'O'),\n",
              " ('be', 'O'),\n",
              " ('Do', 'QUESTION'),\n",
              " ('we', 'QUESTION'),\n",
              " ('need', 'QUESTION'),\n",
              " ('to', 'QUESTION'),\n",
              " ('have', 'QUESTION'),\n",
              " ('a', 'QUESTION'),\n",
              " ('CRM', 'QUESTION'),\n",
              " ('solution', 'QUESTION'),\n",
              " ('to', 'QUESTION'),\n",
              " ('use', 'QUESTION'),\n",
              " ('Avnio', 'QUESTION'),\n",
              " ('?', 'QUESTION'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jfQ7z4A3nGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting the chunks from NER\n",
        "ques = []\n",
        "i=0\n",
        "while i<len(result):\n",
        "  if result[i][1]=='QUESTION':\n",
        "    s=''\n",
        "    while result[i][1]!='O':  \n",
        "      s=s+result[i][0]+' '\n",
        "      i=i+1\n",
        "    ques.append(s.strip())\n",
        "  i=i+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q9Eoy9v8Urm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e55be855-6880-4135-ab3a-245a3ce13f02"
      },
      "source": [
        "#the questions asked in the sample string were:\n",
        "#next we shall use multi label classification to caregorise these questions type\n",
        "ques"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What is your Compliance ?',\n",
              " 'Do we need to have a CRM solution to use Avnio ?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgPDoJPG8YUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}